# Async Delta Inference 使用指南

## 简介

`async_delta_inference` 是对 `async_inference` 框架的扩展，使其支持仿真环境（如 Libero）。通过最小化改动原始代码，实现了在仿真环境中使用异步推理的功能。

## 核心特点

- ✅ **完全复用** PolicyServer（无需修改）
- ✅ **支持 Libero** 仿真环境
- ✅ **自动评估** 多个 episode 并统计成功率
- ✅ **动作聚合** 支持多种策略
- ✅ **最小改动** 保持与原框架一致

## 快速开始

### 方法一：使用快速启动脚本

**Linux/Mac:**
```bash
chmod +x examples/async_delta_inference/quick_start.sh
./examples/async_delta_inference/quick_start.sh
```

**Windows:**
```cmd
examples\async_delta_inference\quick_start.bat
```

### 方法二：手动启动

**步骤 1: 启动 PolicyServer**（终端 1）
```bash
python -m lerobot.async_inference.policy_server \
    --host=127.0.0.1 \
    --port=8080 \
    --fps=30
```

**步骤 2: 启动 SimClient**（终端 2）
```bash
python src/lerobot/async_delta_inference/sim_client.py \
    --env.type=libero \
    --env.task=libero_10 \
    --policy_type=act \
    --pretrained_name_or_path=lerobot/act_libero_10 \
    --policy_device=cuda \
    --actions_per_chunk=50 \
    --n_episodes=10
```

### 方法三：使用 Python API

```python
from lerobot.async_delta_inference import SimClient, SimClientConfig
from lerobot.envs.configs import LiberoEnv
import threading

# 配置
env_config = LiberoEnv(task="libero_10", fps=30)
config = SimClientConfig(
    env=env_config,
    policy_type="act",
    pretrained_name_or_path="lerobot/act_libero_10",
    policy_device="cuda",
    actions_per_chunk=50,
    n_episodes=10,
)

# 运行
client = SimClient(config)
client.start()

action_thread = threading.Thread(target=client.receive_actions, daemon=True)
action_thread.start()

client.control_loop(task="")
client.stop()
```

## 主要参数说明

### 环境参数
- `--env.type`: 环境类型（`libero`）
- `--env.task`: 任务套件
  - `libero_10`: 10 个长期任务
  - `libero_90`: 90 个长期任务
  - `libero_spatial`: 空间推理
  - `libero_object`: 物体操作
  - `libero_goal`: 目标条件

### 策略参数
- `--policy_type`: 策略类型（`act`, `diffusion`, `smolvla` 等）
- `--pretrained_name_or_path`: 模型路径
- `--policy_device`: 设备（`cuda`, `cpu`, `mps`）
- `--actions_per_chunk`: 每次推理生成的动作数量（默认 50）

### 控制参数
- `--chunk_size_threshold`: 发送新观察的阈值（0.0-1.0，默认 0.5）
  - 越小 = 越频繁推理
  - 越大 = 越依赖缓存动作
- `--aggregate_fn_name`: 动作聚合策略
  - `weighted_average`: 加权平均（推荐）
  - `latest_only`: 只用最新
  - `average`: 简单平均
  - `conservative`: 保守策略
- `--fps`: 控制频率（默认 30）

### 评估参数
- `--n_episodes`: 评估的 episode 数量（默认 10）

## 输出示例

```
[sim_client] Creating simulation environment: libero
[sim_client] Simulation environment ready
[sim_client] Connected to policy server in 0.0023s
[sim_client] Action receiving thread starting
[sim_client] Control loop thread starting
[sim_client] Episode 1/10 finished | Steps: 127 | Reward: 1.0000 | Success: True
[sim_client] Episode 2/10 finished | Steps: 134 | Reward: 1.0000 | Success: True
...
============================================================
Evaluation complete!
Episodes: 10
Average Reward: 0.9500
Success Rate: 95.00%
============================================================
```

## 架构说明

```
┌─────────────────────┐      gRPC      ┌─────────────────────┐
│   SimClient         │ ◄────────────► │  PolicyServer       │
│                     │                │  (原有的，未修改)    │
│  - Libero 环境      │  观察 ──────►  │  - 策略模型         │
│  - 动作队列         │                │  - 预处理器         │
│  - 观察发送器       │  ◄────── 动作  │  - 后处理器         │
└─────────────────────┘                └─────────────────────┘
```

## 常见问题

### 1. 连接失败
**现象**: `Failed to connect to policy server`

**解决**:
- 确认 PolicyServer 正在运行
- 检查端口 8080 是否被占用
- 确认防火墙允许本地连接

### 2. 环境错误
**现象**: 找不到 libero 模块

**解决**:
```bash
pip install -e ".[libero]"
```

### 3. GPU 内存不足
**现象**: CUDA out of memory

**解决**:
- 使用较小的模型
- 减少 `actions_per_chunk`
- 使用 CPU: `--policy_device=cpu`

### 4. 推理速度慢
**解决**:
- 检查 GPU 是否被正确使用
- 增加 `chunk_size_threshold` 减少推理频率
- 降低 FPS 设置

## 调试技巧

### 启用详细日志
在启动时添加环境变量：
```bash
export LOG_LEVEL=DEBUG
python src/lerobot/async_delta_inference/sim_client.py ...
```

### 可视化动作队列
```bash
python src/lerobot/async_delta_inference/sim_client.py \
    ... \
    --debug_visualize_queue_size=True
```

### 查看日志文件
日志文件保存在 `logs/` 目录：
- `logs/sim_client_*.log`: 客户端日志
- `logs/policy_server_*.log`: 服务器日志

## 性能优化建议

### 降低延迟
1. 使用更快的 GPU
2. 减少图像分辨率（在环境配置中）
3. 增大 `chunk_size_threshold`（依赖更多缓存动作）

### 提高稳定性
1. 使用 `weighted_average` 聚合函数
2. 适当降低 FPS
3. 增加 `actions_per_chunk`

### 批量评估
```bash
# 评估更多 episodes 以获得可靠的统计
--n_episodes=50
```

## 与原框架的对比

| 特性 | async_inference | async_delta_inference |
|------|----------------|----------------------|
| 硬件 | 真实机器人 | 仿真环境 |
| PolicyServer | 需要 | 完全复用 |
| 观察获取 | robot.get_observation() | env.step() |
| 动作执行 | robot.send_action() | env.step(action) |
| 运行模式 | 持续运行 | 固定 episodes |
| 评估指标 | 无 | 自动统计 |

## 扩展支持

目前支持的环境：
- ✅ Libero
- 🔜 MetaWorld（即将支持）

要添加新环境，参考 `constants.py` 中的 `SUPPORTED_ENVS`。

## 文件清单

```
src/lerobot/async_delta_inference/
├── __init__.py              # 模块初始化
├── configs.py              # SimClientConfig
├── constants.py            # 常量
├── sim_client.py           # 核心实现
├── README.md              # 英文文档
└── 使用指南.md             # 中文文档（本文件）

examples/async_delta_inference/
├── evaluate_libero.py      # Python API 示例
├── quick_start.sh          # Linux/Mac 启动脚本
├── quick_start.bat         # Windows 启动脚本
└── README.md              # 示例说明
```

## 贡献与反馈

如有问题或建议：
1. 检查本文档和 README.md
2. 查看日志文件排查问题
3. 在 GitHub 提交 issue

---

**提示**: 第一次运行时，模型下载可能需要一些时间。确保网络连接正常。

